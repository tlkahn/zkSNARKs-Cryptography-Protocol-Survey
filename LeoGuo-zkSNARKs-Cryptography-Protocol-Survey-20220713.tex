% Created 2022-07-14 Thu 18:18
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[backend=biber, natbib=true, style=alphabetic, sorting=ynt]{biblatex}
\addbibresource{/Users/toeinriver/Dropbox/emacs/bibliography/references.bib}
\usepackage{xcolor}
\hypersetup{colorlinks, linkcolor={red!50!black}, citecolor={blue!50!black}, urlcolor={blue!80!black}}
\usepackage{verbatimbox}
\usepackage{markdown}
\usepackage{framed}
\usepackage{quoting}
\colorlet{shadecolor}{gray!20}
\newenvironment{shadedquotation}{\begin{shaded*} \quoting[leftmargin=0pt, vskip=0pt]}{\endquoting\end{shaded*}}
\usepackage[width=.75\textwidth]{caption}
\usepackage{float}
\usepackage{rotating}
\author{Leo Guo}
\date{\today}
\title{zkSNARKs Cryptography Protocol Survey}
\hypersetup{
 pdfauthor={Leo Guo},
 pdftitle={zkSNARKs Cryptography Protocol Survey},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 29.0.50 (Org mode 9.5.1)},
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents \clearpage
\section{zkSNARKs Cryptography Protocol Survey}
\label{sec:org6cd323c}
\subsection{Basic information}
\label{sec:org1623320}

\begin{longtable}{|p{2cm}|p{10cm}|}
\hline
Item & zkSNARKs Cryptography Protocol Survey\\
Name & Leo Guo\\
Discord Account & toeinriver7694\\
Study Group & team3\\
Assignment & zkSNARKs Cryptography Protocol Survey\\
GitHub & \url{https://github.com/tlkahn/zkSNARKs-Cryptography-Protocol-Survey}\\
\hline
\end{longtable}

\subsection{Research scope}
\label{sec:org7b9e5d2}
We use the term SNARK for what is sometimes called a "SNARK with pre-processing" (see e.g. \cite{10.1007/978-3-642-38348-9_37}) where one allows a one-time verifier computation that is polynomial rather than polylogarithmic (or linear) to the circuit size. This limit our discussion to SNARKs with universal or circuit-specific SRSs, so the proof is fully succinct \footnote{A zk-SNARK for circuit satisfiability is fully succinct if: 1) The pre-processing phase/SRS generation run time is quasilinear in circuit size. 2) The prover run time is quasilinear in circuit size. 3) The proof length is logarithmic in circuit size. 4) The verifier run time is polylogarithmic in circuit size.\label{org96351aa}} or equivalent. In return, the SNARK is expected to work for all non-uniform circuits, rather than only statements about uniform computation.

As the following diagram (from Alessandro Chiesa's \href{https://www.youtube.com/watch?v=-EkUn4iD8Z8}{State of the SNARG-scape speech}) illustrated:

\begin{center}
\includegraphics[width=.9\linewidth]{./snarg-scape.png}
\end{center}

the research scope of this survey will be focusing on the SNARKs in the right two columns (under structured reference string, i.e. universal and circuit-specific). The constructions on the left side, such as STARK, Fractal, Bulletproofs etc. will be left for future work.

The only exception is Halo. Due to the special (growing) importance of recursive SNARKs, Halo will be included in the scope.


\subsection{Overview}
\label{sec:orgc7e093b}
zkSNARK is one of the most important Zero-Knowledge Proof (ZKP) methods used in privacy computing and blockchain technology. zkSNARK stands for: zero-knowledge Succinct Non-Interactive ARgument of Knowledge, which is a protocol through which a prover can quickly convince a verifier on knowledge of a secret without revealing anything about it. Nir Bitansky, Ran Canetti, Alessandro Chiesa, and Eran Tromer introduced the term zk-SNARKs in 2012 \cite{2012}
The core theoretical components of zkSNARK are summarized below:
\begin{itemize}
\item zero-knowledge (zk)
According to Goldwasser, Micali, and Rackoff \cite{1985}, who first introduced the "zero-knowledge” concept as "\emph{Zero-knowledge proofs are defined as those proofs that convey no additional knowledge other than the correctness of the proposition in question}". There are three essential attributes of zk featuring protocols:
\begin{itemize}
\item Completeness: If the statement is true, then the verifier always accepts the proof \(\pi\).
\item Soundness: If the statement is false, then the prover can only convince the verifier with a negligible probability.
\item Zero-knowledge: a correct proof \(\pi\) does not leak any information about the secret.
\end{itemize}
\item Succinctness (S)
The first constructions of SNARK protocols were inspired by the PCP theorem \cite{10.1145/273865.273901} which shows that NP statements have "short" Probabilistic Checkable Proofs (PCP). New instantiations were found which allow faster and shorter proofs, when a pre-processing state is permitted. With proper pre-processing and arithmetization, the proof becomes realistically feasible w.r.t proof size, running time, verification time etc. The formal definition is below \cite{2012}:

\begin{quote}
\begin{shadedquotation}
  The length of the proof \(\Pi\) that \(\mathcal{P}(y,w,vgrs)\) outputs, as well as the running time of \(\mathrm{nu}(priv, y, \Pi)\), is bounded by:

  \[
  p(k+\lvert y \rvert) = p(k + \lvert M \rvert + \lvert x \rvert + log t)
  \]

  where \(p\) is a universal polynomial that does not depend on \(\mathcal{R} \subseteq \mathcal{R}_\mathcal{U}\). \(\mathcal{R}_\mathcal{U}\) is the universal relation \cite{10.5555/872747.873184}, a.k.a the set \(\mathcal{R}_\mathcal{U}\) of instance-witness pairs \((y, w)\), where \(y=(M, x, t), \lvert w \rvert \le t\) and \(M\) is a Turing machine such that $M$ accepts \((x,w)\) after at most \(t\) steps.
\end{shadedquotation}
\end{quote}

\item "Non-interactive" (N) means the prover can publish a single one-way message to the verifiers, with no need of further back-and-forth interactions.
\item "ARguments" (AR): An argument system for an NP relationship \(\mathcal{R}\) is a protocol between a computationally-bounded prover \(P\) and a verifier \(V\). AR in SNARK means \(V\) is only protected against computationally-bounded \(P\). Provers with computationally unlimited power can fake proofs/arguments on wrong statements. This requirement is also called “computational soundness”, as opposed to “perfect soundness”. \footnote{Christian Reitwiessner's blog: \href{https://blog.ethereum.org/2016/12/05/zksnarks-in-a-nutshell/}{zkSNARKs in a nutshell}\label{org4bb40a3}}
\item "of Knowledge":

SNARKs are SNARGs where computational soundness is replaced by knowledge soundness, which roughly means the prover is not able to construct a proof without knowing the witness \(w\). \textsuperscript{\ref{org4bb40a3}}
\end{itemize}

\subsection{Big idea}
\label{sec:orgaaa6b2e}
As the name hints, zkSNARKs have four main components \textsuperscript{\ref{org4bb40a3}}:

\begin{itemize}
\item Encoding the problem as a polynomial

The problems are compiled into polynomials, e.g. \(t(x)h(x) = w(x)v(x)\), the Quadratic Span Programs (QSP) as in \cite{10.1007/978-3-642-38348-9_37}, where the equality holds \emph{iff} the program is computed correctly. The prover convinces the verifier that the above equality holds. The formal definition in \cite{2012} is:

\begin{quote}
\begin{shadedquotation}
... membership of an instance $y$ in an $NP$ language $L$ can be verified in time that is bounded by $p(k, \lvert y \rvert, \log t)$, where $t$ is the time to evaluate the $NP$ verification relation for $L$ on input $y$, $p$ is a fixed polynomial independent of $L$, and $k$ is a security parameter that determines the soundness error.
\end{shadedquotation}
\end{quote}

In general, zkSNARKs can be contructed from four categories \cite{Nitulescu2020zkSNARKsAG}:

\begin{itemize}
\item PCP

The oldest SNARK construction methodology is explained:

\begin{quote}
\begin{shadedquotation}
\ldots{}is based on PCP characterization of NP, and it is first achieved in the random oracle model (ROM), which gave only heuristical security. The idea is to apply the random oracle-based Fiat-Shamir transform to Kilian’s succinct PCP-based proof system [Kil92], achieving logarithmic proof size and verification time. Later, the construction is improved by removing the use of the random oracles and replacing them with extractable collision-resistant hash functions (ECRH).

The work of [CL08] proposed the PCP + Merkle Tree (MT)+ Private Information Retrieval (PIR) approach to “squash” Kilian’s four-message protocol into a two-message protocol.

In both cases, we do not obtain knowledge soundness, but only plain adaptive soundness.
\end{shadedquotation}
\end{quote}

\item QAP

The most popular and widely implemented SNARK construction shares a central starting point on quadratic programs introduced by \cite{10.1007/978-3-642-38348-9_37}. The proof/verification framework build SNARKs for programs encoded as boolean or arithmetic circuits.

\begin{quote}
\begin{shadedquotation}
/Arithmetic Circuits/: Informally, an arithmetic circuit consists of wires that carry values from a field F and connect to addition and multiplication gates.

/Boolean Circuits/: A boolean circuit consists of logical gates and of a set of wires between the gates. The wires carry values over {0, 1}.
\end{shadedquotation}
\end{quote}

This approach has led to fast progress towards practical verifiable computations. The first implementation is Pinocchio \cite{6547113}.

\begin{quote}
\begin{shadedquotation}
A SNARK scheme for a circuit has to enable verification of proofs for (Arithmetic or Boolean) Circ-SAT problem, i.e., a prover, given a circuit ($\mathcal{C}$) has to convince the verifier that it knows an assignment of its inputs that makes the output true.
\end{shadedquotation}
\end{quote}

Circ-SAT problem is the NP-complete decision problem of determining whether a given circuit has an assignment of its inputs that makes the output true. A very important line of works focuses on building SNARKs for circuit satisfiability and have as a central starting point the framework based on quadratic span programs (QSP) \cite{10.1007/978-3-642-38348-9_37}. QSP consists of multiple polynomials \(\nu_0, \dots, \nu_i; \omega_0, \dots, \omega_i\) over a Galois field \(F\) and a target polynomial \(t\). The QSP is accepted \emph{iff} \(t\) divides \(\nu_a \times \omega_b\) where \(nu_a\) and \(\omega_b\) is constructed from the witness \(w\) and the original polynomials \(\nu_0, \dots, \nu_i; \omega_0, \dots, \omega_i\).

Further more, QSP can be improved by QAP. \cite{Nitulescu2020zkSNARKsAG}

\begin{quote}
\begin{shadedquotation}
Parno eta. \cite{6547113} defined QAP,a similar notion for arithmetic circuits,namely Quadratic Arithmetic Programs (QAP). More recently, an improved version for boolean circuits, the Square Span Programs (SSP) was presented which consequentially has led to a simplified version for arithmetic circuits, Square Arithmetic Programs (SAP), proposed in \cite{10.1007/978-3-319-63715-0_20}.
\end{shadedquotation}
\end{quote}

\item Linear Interactive Proof (LIP)

According to \cite{Nitulescu2020zkSNARKsAG},

\begin{quote}
\begin{shadedquotation}
The QAP approach was generalized under the concept of Linear Interactive Proof (LIP), a form of interactive ZK proofs where security holds under the assumption that the prover is restricted to compute only linear combinations of its inputs.

These proofs can then be turned into (designated-verifier) SNARKs by using an extractable linear-only encryption scheme.
\end{shadedquotation}
\end{quote}

\item Polynomial Interactive Oracle Proof (PIOP)

According to \cite{Nitulescu2020zkSNARKsAG}:

\begin{quote}
\begin{shadedquotation}
As we saw previously, SNARKs are commonly build in a modular way. Recent works propose schemes that follow a new framework, enabling more possibilities such as: \textbf{transparent constructions (without a trusted setup), recursion, aggregation properties, post-quantum security}, etc.

Modular instantiations of recent SNARKs employs polynomial \emph{interactive oracle proofs (IOP)} for the information theoretic step, and \emph{polynomial commitments} for the cryptographic compilation. One advantage of using polynomial commitments is that \textbf{the setup is only needed for the commitment scheme and is thus independent of the statement being proven.} This allows these SNARKs to be \textbf{universal} as opposed to the circuit-based SNARKs presented in the previous section. Another advantage is that the choice of polynomial commitment scheme facilitates finding the right trade-off between performance and security.

To build such SNARKs, one commonly follows 3 steps:

\begin{itemize}
\item NP Characterization or Arithmetization for Circuits:

Start with a way to describe the computation to be proven as a system of constraints involving native operations over a finite field. Then, this system of constraints can be changed into a (low-degree) \textbf{univariate polynomial expression}.

\item Polynomial IOP or Algebraic Holographic Proofs:

The proof consists in finding a way to show that such a polynomial equation holds. In a Polynomial Interactive Oracle Proof (PIOP), the prover sends low degree polynomials to the verifier, and rather than reading the entire list of coefficients, the verifier queries evaluations of these polynomials in a random point to an oracle interface.

\item Cryptographic Compiler.

Using polynomial commitment schemes and Fiat-Shamir heuristic, the previous checks can be compiled into an efficient and non-interactive proof system. The resulting zk-SNARK has either universal updatable structured reference string (SRS), or transparent setup, depending only on the nature of the polynomial commitment scheme used in this step.

Remark that the only step where we employ cryptographic techniques is the final one. In this cryptographic compilation step the oracles from before are replaced by a suitable cryptographic realization: Polynomial Commitments (PC) in Sonic, Marlin and Plonk (\cite{inproceedings}, \cite{inproceedings}, \cite{Gabizon2019PLONKPO}). \footnote{The computation of polynomial commitment can be optimized by table lookup. \cite{Gabizon2020plookupAS}} Polynomial commitments allow to check efficiently a series of identities on low-degree polynomials resulting from the arithmetization step. This comes at the expense of introducing computational hardness assumptions for security and sometimes a trusted setup.
\end{itemize}
\end{shadedquotation}
\end{quote}

A typical modern zkSNARK process can be illustrated as follows:

\begin{center}
\includegraphics[width=.9\linewidth]{./snark-process.png}
\end{center}

Source of the above image is unknown, meanwhile it appears to be frequently credited to cryptographer Eran Tromer.

Polynomial commitments e.g. KZG, are a commitment scheme introduced by \cite{Kate} which are extremely powerful constructs that allow a prover to commit a polynomial and show evaluations of that polynomial on any point with a single group element-sized proof in constant time. As such, Kate commitments and its variants lie at the heart of many PIOP-style zkSNARK constructions (such as Marlin and PLONK).
\end{itemize}

\item Succinctness by random sampling

The verifier randomly samples a secret input \(s\) for evaluation with the polynomials, thus reducing the problem from polynomials operations to simple evaluation on numbers, e.g. \(t(s) h(s) = w(s) v(s)\)

\item Homomorphic encoding/encryption

An encoding/encryption function \(e\) is used that has some homomorphic properties. Combining the research on pairing-based double homomorphic encryption scheme \cite{10.1007/978-3-540-30576-7_18} and NIZK leads to the solution on unconditional zero-knowledge:

\begin{longtable}{|p{2cm}|l|l|}
\hline
ZK proof for NP-complete languages & Computational zero knowledge & Unconditional zero knowledge\\
\hline
\endfirsthead
\multicolumn{3}{l}{Continued from previous page} \\
\hline

ZK proof for NP-complete languages & Computational zero knowledge & Unconditional zero knowledge \\

\hline
\endhead
\hline\multicolumn{3}{r}{Continued on next page} \\
\endfoot
\endlastfoot
\hline
Interactive & Goldreich-Wigderson-Micali 1986 & Brassard-Crépeau 1986\\
\hline
Non-interactive & Blum-Feldman-Micali 1988 & Groth-Ostrovsky-Sahai 2006\\
\hline
\end{longtable}

\begin{itemize}
\item Core idea (\cite{10.1007/11761679_21}) to prove circuit satisfiability with zk \footnote{Jens Groth's lecture \href{https://www.youtube.com/watch?app=desktop\&v=X-z3JYlFdzs\&feature=youtu.be}{Bilinear Pairings-based Zero-Knowledge Proofs}}:

\begin{itemize}
\item Commit to wire values in circuit as \(g^a h^r, g^b h^s, g^c h^t, \dots\)
\item Verifier can easily add committed elements: \(g^a h^r \cdot g^b h^s = g^{a+b} h^{r+s}\)
\item Prover can demonstrate multiplicative relation: \(e(g^a h^r, g^b h^s) = e(g^c h^t, g) e(\pi, h)\)
\end{itemize}
\end{itemize}

\item Obfuscation

The prover obfuscates the values \(e(g^a h^r, g^b h^s), e(g^c h^t, g), e(\pi, h)\) by multiplying with a non-zero secret point \(k\) from the contextual elliptic curve (EC) on both sides, thus the verifier can still verify the correctness on hidden values.
\end{itemize}

\subsection{Theoretical development}
\label{sec:org2036059}
\subsubsection{Pre-Pinocchio}
\label{sec:orga3d3678}

Based on the retrospective summary by \cite{6547113},

\begin{quote}
\begin{shadedquotation}
Considerable systems and theory research has looked at the problem of verifying computation. However, most of this work has either been function specific, relied on assumptions we prefer to avoid, or simply failed to pass basic practicality requirements. Function specific solutions are often efficient, but only for a narrow class of computations. More general solutions often rely on assumptions that may not apply. For example, systems based on replication assume uncorrelated failures, while those based on Trusted Computing or other secure hardware assume that physical protections cannot be defeated. Finally, the theory community has produced a number of beautiful, general purpose protocols (\cite{1985}, \cite{10.1145/129712.129782}, \cite{10.1137/S0097539795284959}, \cite{10.1145/2699436}, \cite{10.1007/978-3-642-17373-8_19}, \cite{10.1007/978-3-642-14623-7_25}, \cite{10.1007/978-3-642-14623-7_26}, \cite{10.5555/1834954}), that offer compelling asymptotics. In practice however, because they rely on complex Probabilistically Checkable Proofs (PCPs) \cite{10.1145/273865.273901} or fully-homomorphic encryption (FHE) \cite{10.5555/1834954}, the performance is unacceptable – verifying small instances would take hundreds to trillions of years\ldots{}
\end{shadedquotation}
\end{quote}

\subsubsection{Pinocchio}
\label{sec:orgdb1bcb9}

Pinocchio \cite{6547113} was the first \textbf{practical} implementation of a zk proving system; for instance, before adoption of \cite{groth_size_nodate}, earliest version of zCash implemented Pinocchio to deliver their original shielded transaction protocol \cite{DBLP:journals/corr/abs-2008-00881}. (\emph{Heavily quoted from \cite{6547113} below}).

\begin{quote}
\begin{shadedquotation}
  \begin{itemize}
  \item Major features

  \begin{itemize}
  \item Supports public verifiable computation, which allows an untrusted worker to produce signatures of computation

  \item Supports zero-knowledge verifiable computation, in which the worker convinces the client that it knows an input with a particular property, without revealing any information about the input.

  \item Verification time is typically 10ms: 5-7 orders of magnitude less than previous work.

  \item The first general-purpose system to demonstrate verification cheaper than native execution (for some apps).

  \item Reduces the worker’s proof effort by an additional 19-60\(\times\)

  \item Generalizes to zero-knowledge proofs at a negligible cost over the base protocol.

  \item Provides an end-to-end toolchain that compiles a subset of C into programs that implement the verifiable computation protocol.
  \end{itemize}

  \item Design ideas

  To achieve efficient verifiable computation, Pinocchio combines quadratic programs (QSP), a computational model introduced by Gennaro et al. \cite{10.1007/978-3-642-38348-9_37}, with a series of theoretical refinements and systems engineering to produce an end-to-end toolchain for verifying computations. Specifically, via an improved protocol and proof technique, we slash the cost of key generation by 61%, and the cost of producing a proof by 64%.

  From a developer’s perspective, Pinocchio provides a \emph{circuit compiler} that transforms C code into a circuit representation (both Boolean and arithmetic supported), thus converts the circuit into a quadratic program, and then generates programs to execute the cryptographic protocol.

  \begin{center}
  \includegraphics[width=.9\linewidth]{./Pinocchio toolchain.png}
  \end{center}
  \end{itemize}

  \begin{itemize}
  \item Contributions

  \begin{enumerate}
  \item An end-to-end system for efficiently verifying computation performed by one or more untrusted workers. This includes a compiler that converts C code into a format suitable for verification, as well as a suite of tools for running the actual protocol.

  \item Theoretical and systems-level improvements that bring performance down by 5-7 orders of magnitude, and hence into the realm of plausibility.

  \item An evaluation on seven real C applications, showing verification faster than 32-bit native integer execution for some apps.
  \end{enumerate}
  \end{itemize}
\end{shadedquotation}
\end{quote}

\subsubsection{Groth16}
\label{sec:orgda127a8}

In 2016, Jens Groth formalized a proving system that significantly improved performance \cite{groth_size_nodate} compared to Pinocchio.

Despite the requried trusted setup, Groth16 currently remains the fastest known zk-SNARK with the smallest proof size. Groth16's trusted setup is per circuit thus non-universal. \footnote{\href{https://medium.com/coinmonks/comparing-general-purpose-zk-snarks-51ce124c60bd}{Comparing General Purpose zk-SNARKs}} New SNARKs often use Groth16 as the performance benchmark.

Below are heavily quoted from \cite{groth_size_nodate} and \cite{Nitulescu2020zkSNARKsAG}:

\begin{quote}
\begin{shadedquotation}
\begin{itemize}
\item Major features

\begin{itemize}
\item For arithmetic circuits, Groth16 proofs consist of only 2 elements in G1 and 1 in G2, compared to Pinocchio’s 7 elements in G1, and 1 in G2.

\item Verification is faster. Verifiers need to compute a number of exponentiations proportional to the statement size and check a single pairing product equation with just 3 pairings instead of 12.

\item Shorter CRS.

\item The construction can be instantiated with any type of pairings including Type III pairings \cite{pairing_guide}, which are the most efficient pairings.
\end{itemize}

Based on the observation of "arithmetic circuit satisfiability in the Table, of the size of the common reference string (CRS), the size of the proof, the prover’s computation, the verifier’s computation, and the number of pairing product equations used to verify a proof", Groth16 performs better than the state of the art on all efficiency parameters when published.

\begin{figure}[H]
\centering
\includegraphics[width=.9\linewidth]{./groth16-comp.png}
\caption{Comparison for arithmetic circuit satisfiability with \(\ell\)-element statement, \(m\) wires, \(n\) multiplication gates.}
\end{figure}

\item Design ideas.

Groth16's construction is simplified compared to the one in \cite{6547113}. Popular research \cite{Nitulescu2020zkSNARKsAG} have observed that the proof elements are not duplicated with respect to some random factor and this is not needed for the extraction, since the security relies on a stronger model, the Generic Group Model(GGM) and not on q-PKE assumption.

The Generic Group Model \cite{10.1007/3-540-69053-0_18}, \cite{Maurer05} is an idealized cryptographic model, where algorithms do not exploit any special structure of the representation of the group elements and can thus be applied in any cyclic group. In this model, the adversary is only given access to a randomly chosen encoding of a group, instead of efficient encodings, such as those used by the finite field or elliptic curve groups used in practice. The model includes an oracle that executes the (additive) group operation. Therefore, one can efficiently extract the coefficients used to express an output of the oracle as a linear combination of initial group elements.

To describe Groth’s construction, we consider the relation \(\mathcal{R}\) implemented as an arithmetic circuit for a total number of wires \(m\). We denote by \(\mathcal{T}_{io} ={1,2,\dots \ell}\), the indices corresponding to the public input and public output values of the circuit wires (corresponding to the statement \(u\)) and by \(\mathcal{T}_{mid} = {\ell+1, \dots m}\), the wire indices corresponding to private input and non-input, non-output intermediate values (for the witness \(w\)).

\hyperref[fig:org19d835f]{Below} is the birdview of Groth16's algorithm.
\end{itemize}


\begin{figure}[H]
\centering
\includegraphics[width=400px]{./groth16-architecture.png}
\caption{\label{fig:org19d835f}Groth16 Construction from QAP.}
\end{figure}


\begin{itemize}
\item Contributions

\begin{itemize}
\item Our first contribution is a pairing-based (pre-processing) SNARK for arithmetic circuit satisfiability, which is an NP-complete language. In our SNARK we work with:

\begin{enumerate}
\item \emph{asymmetric pairings} for higher efficiency,

\item a proof is only 3 group elements

\item verification consists of checking \emph{a single pairing product equations using 3 pairings in total}.
\end{enumerate}

\item As our second contribution we answer an open question of Bitansky, Chiesa, Ishai, Ostrovsky and Paneth (TCC 2013) by showing that \emph{2-move linear interactive proofs cannot have a linear decision procedure}. It follows from this that \emph{SNARGs where the prover and verifier use generic asymmetric bilinear group operations cannot consist of a single group element}. This gives the \emph{first lower bound for pairing-based SNARGs}. It remains an intriguing open problem whether this lower bound can be extended to rule out 2 group element SNARGs, which would prove optimality of our 3 element construction.
\end{itemize}
\end{itemize}
\end{shadedquotation}
\end{quote}

\subsubsection{Sonic}
\label{sec:orge7e69f3}

Sonic \cite{inproceedings} is an early general purpose zk-SNARK protocol. The paper was published in January 2019. Sonic supports a universal and updatable SRS. Sonic proofs are constant size, but verification is expensive. In theory, multiple proofs can be verified in batches to achieve better performance. Many modern zk-SNARKs are based on Sonic. Sonic is the first fully succinct NIZK with SRS. \textsuperscript{\ref{org96351aa}}

What follows are heavily quoted from \cite{inproceedings} and \cite{Nitulescu2020zkSNARKsAG}:

\begin{quote}
\begin{shadedquotation}
  \begin{itemize}
  \item Major features:

  \begin{itemize}
  \item Universal and continuously updatable SRS that scales linearly in size.

  \item Arithmetization for circuits

  Sonic represents the circuit as three vectors of left, right, and output wires. Then, the consistency of both the multiplication gates and the linear constraints are reduced to one large polynomial equation in a variable \(Y\). The equation is then embedded into the \(X^0\) terms of a bivariate polynomial \(t(X, Y)\). The verifier will check that the prover computed the bivariate polynomials from witness and circuit specific bivariate polynomials such that the \(X^0\) terms cancel out. Using a PIOP, these bivariate polynomials can be simulated with univariate ones under some conditions.

  \item Polynomial commitment

  As a pairing-based SNARKs and rely on trusted setup, Sonic using a variant of KZG \cite{Kate}. KZG is a pairing-based construction that allows for openings of evaluations on a point with a single group element-sized proof of correct opening and a constant time verifier for this check. More precisely, \(\mathtt{KZG.PC} = (\mathtt{KZG.ComGen}, \mathtt{KZG.Com}, \mathtt{KZG.Open}, \mathtt{KZG.Check})\) is defined over bilinear groups \(gk=(p,\mathbb{G}_1, \mathbb{G}_2, \mathbb{G}_T)\) with \(\mathbb{G}_1 =  \langle g \rangle, \mathbb{G}_2 = \langle h \rangle\) as follows:

  \begin{center}
  \includegraphics[width=300px]{./kzg.png}
  \end{center}

  \item Batched verifications and potential of improved efficiency

  Sonic presented a generally useful technique in which untrusted "helpers" can compute advice that allows batches of proofs to be verified more efficiently. Sonic proofs are constant size, and in the “helped” batch verification context the marginal cost of verification is comparable with the most efficient SNARKs in the literature.
  \end{itemize}

  \item Design ideas:

  \begin{itemize}
  \item The best of both worlds:

  At the time Sonic was invented, the most efficient scheme described in the literature is Groth16 which contains only three group elements. Typically, such zkSNARKs require a trusted setup, a pairing-friendly elliptic curve, and rely on strong assumptions.

  In contrast, proving systems such as Bulletproofs \cite{8418611} do not require a trusted setup and depend on weaker assumptions. Unfortunately, although its proof sizes scale logarithmically with the relation size, Bulletproof verification time scales linearly, even when applying batching techniques. As a result, Bulletproofs are good for simple relations but with limited practicality in real-world applications.

  The trusted setup has emerged as a barrier for deployment and wide adoption.

  The research in \cite{10.1007/978-3-319-96878-0_24}, which proposed the first universal SRS that allows a single setup to support all circuits of some bounded size, which is also updatable, meaning that an open and dynamic set of participants can contribute secret randomness to it indefinitely. The drawback is that it requires an SRS that is quadratic with respect to the number of multiplication gates in the supported arithmetic circuits. In a concrete setting such as ZCash, which has a circuit with 217 multiplication gates, the SRS would be on the order of terabytes and is thus prohibitively expensive. Moreover, updating the SRS requires a quadratic number of group exponentiations, and verifying the updates requires a linear number of pairings. Expensive Gaussian elimination process is also involved in computing SRS.

  \item Core technique

  \begin{itemize}
  \item Two-variate polynomial equation

  \ldots{} Sonic defines its constraint system with respect to the two-variate polynomial equation used in Bulletproofs \cite{8418611}.

  In the Bulletproof's polynomial equation, there is one polynomial that is determined by the instance of the language and a second that is determined by the constraints.

  The polynomial determined by the instance \(\bf{a}\) is given by:

  \[
              \sum_{i,j} a_{i,j} X^i Y^j
  \]

  Each element of the instance is used to scale a monomial in the overall polynomial. For this reason, an SRS that contains only hidden monomial evaluations suffices for committing to the instance. Groth et al. \cite{10.1007/978-3-319-96878-0_24} showed that an SRS that contains monomials is updatable; the second polynomial that is determined by the constraints is known to the verifier. Sonic uses this knowledge to allow the verifier to obtain evaluations of the polynomial while avoiding putting constraint-specific secrets in the SRS.

  \item Polynomial Commitment

  Sonic use KZG \cite{Kate} for polynomial commitment. Sonic proved the commitment scheme secure in the Algebraic Group Model \cite{10.1007/978-3-319-96881-0_2}, which is a model that lies somewhere between the standard model and the generic group model. KZG scheme has constant size and verification time, but is designed for single-variate polynomials, whereas Sonic use two-variate. To account for this, Sonic hid only one evaluation point in the reference string.
  \end{itemize}
  \end{itemize}
  \end{itemize}


  \begin{itemize}
  \item Main contributions:

  \begin{itemize}
  \item Updatable universal SRS: Sonic requires a trusted setup, but unlike conventional SNARKs the structured reference string supports all circuits (up to a given size bound) and is also updatable, so that it can be continually strengthened. This addresses many of the practical challenges and risks surrounding such setups; Sonic’s SRS is linear in size with respect to the size of supported circuits. The SRS does not need to be specialized or pre-processed for a given circuit. This makes a large, distributed and never-ending setup process a practical reality.

  \item Batch proof verification: Sonic consists of a constant number of pairing checks. Unlike other zk-SNARKs, all proof elements are in the same source group, which has several advantages. Most significantly, when verifying many proofs at the same time, the pairing operations need to be computed only once. Sonic also removed the requirement for operations in the second source group, which are typically more expensive.

  \item Succinct Evaluation: Sonic’s verification includes checking the evaluation of a sparse bivariate polynomial in the scalar field. Sonic introduced a method to check this evaluation succinctly (given a circuit-dependent pre-computation) and thus maintain our zk-SNARK properties. Our proof of correct evaluation introduces a new permutation argument and a grand-product argument.

  \item Proof aggregation: Sonic can achieve better concrete efficiency if an untrusted “helper” party aggregates a batch of proofs. This batching operation computes advice to speed up the verifier. In a blockchain application, this helper could be a miner-type client that already processes and verifies transactions for inclusion in the next block.
  \end{itemize}
  \end{itemize}
\end{shadedquotation}
\end{quote}

\subsubsection{Marlin}
\label{sec:orgeacfee6}

Marlin is an improvement on Sonic with 10x better prover time and 4x better verification times.

The following are heavily quoted from \cite{cryptoeprint:2019/1047}.

\begin{quote}
  \begin{shadedquotation}
    \begin{itemize}
    \item Major features
    \begin{itemize}
    \item Fast verification: Marlin exploited a novel use of holography \cite{10.1145/103418.103428}, where fast verification is achieved provided the statement being checked is given in an encoded form.

    \item SRS and argument size: We use our methodology to obtain a pre-processing zkSNARK where the SRS has linear size and arguments have constant size.

    \item Improvements on Sonic \cite{inproceedings} in all efficiency parameters: proving is an order of magnitude faster and verification is thrice as fast, even with smaller SRS size and argument size.

    \item Algebraic Group Model: Our construction is most efficient when instantiated in the algebraic group model (also used by Sonic).
    \end{itemize}
    \item Design ideas
    \begin{center}
    \includegraphics[width=1.2\linewidth]{./marlin-process.png}
    \end{center}
    \item Main contributions
    \begin{itemize}
    \item A new methodology: The methodology in fact produces succinct interactive arguments that can be made non-interactive via the Fiat–Shamir transformation. \cite{10.1007/3-540-47721-7_12}. Marlin's key observation is that the ability to pre-process a circuit in an offline phase is closely related to constructing “holographic proofs” \cite{10.1145/103418.103428}, which means that the verifier does not receive the circuit description as an input but, rather, makes a small number of queries to an encoding of it. These queries are in addition to queries that the verifier makes to proofs sent by the prover. Moreover, Marlin focused on the setting where the encoding of the circuit description consists of low-degree polynomials and also where proofs are themselves low-degree polynomials — this can be viewed as a requirement that honest and malicious provers are “algebraic”, known as Algebraic Holographic Proofs (AHPs).

    \item An efficient AHP for R1CS: Marlin designed an algebraic holographic proof (AHP) that achieves linear proof length and constant query complexity, among other useful efficiency features. The protocol is for rank-1 constraint satisfiability (R1CS), a well-known generalization of arithmetic circuits where the “circuit description” is given by coefficient matrices (see definition below).

    \item Extractable polynomial commitments: Marlin proposed a definition for polynomial commitment schemes that incorporates the functionality and security that suffice for standalone use. Moreover, Marlin shows how to extend the construction of \cite{Kate} to fulfill this definition in the plain model under non-falsifiable knowledge assumptions, or via a more efficient construction in the algebraic group model under falsifiable assumptions.
\end{itemize}
\end{itemize}
\end{shadedquotation}
\end{quote}

\begin{itemize}
\item Darlin: Merlin's evolution with recursive SNARK features:
\end{itemize}

\begin{quote}
\begin{shadedquotation}
...a succinct zero-knowledge argument of knowledge based on the Marlin SNARK \cite{cryptoeprint:2019/1047} and the ‘dlog’ polynomial commitment scheme from \cite{cryptoeprint:2016/263}, \cite{8418611}. Darlin addresses recursive proofs by integrating the amortization technique from Halo \cite{Bowe2020RecursivePC} for the non-succinct parts of the dlog verifier, and we adapt their strategy for bivariate circuit encoding polynomials to aggregate Marlin’s inner sumchecks across the nodes the recursive scheme...
\end{shadedquotation}
\end{quote}

\subsubsection{Plonk}
\label{sec:org5d867d1}
\begin{itemize}
\item Major features

\begin{itemize}
\item Plonk is an improvement on Sonic with a 5\(\times\) better prover time. \cite{Gabizon2019PLONKPO}. Sonic still requires relatively high proof construction overheads. Plonk presented a universal SNARK construction with fully succinct verification, and significantly lower prover running time (roughly 7.5-20 times fewer group exponentiations than \cite{inproceedings} in the fully succinct verifier mode depending on circuit structure).

\item At a high level the improvements stem from a more direct arithmetization of a circuit. Plonk represents the vector of wire values as well as the different gates selectors as polynomials using interpolation.

\item A polynomial division check ensures that the prover knows satisfying inputs and outputs for each gate, but does not ensure a correct wiring, e.g. that the output of one gate is the input to another. Vitalik\footnote{\href{https://vitalik.ca/general/2019/09/22/plonk.html}{Blog post}} described the solution as "copy constraints" encoded with permutation of polynomials. A permutation argument establishes the consistency of the assignment of wires to gates.
\end{itemize}
\item Design ideas

A full formal description can be find in \cite{Gabizon2019PLONKPO} \(\S 8.4\). The core idea is that Plonk relied on a permutation argument over univariate evaluations on a multiplicative subgroup based on \cite{10.1007/978-3-642-29011-4_17}. Plonk focused on evaluation on a subgroup rather than over coefficients of bivariate polynomial as in \cite{inproceedings}.

A more plain rephrase would be: the prover first constructs a series of commitments to various polynomials that represent the constraints represented by circuits. After committing to these values, the prover constructs the opening proofs for these polynomials, which the verifier can verify using elliptic curve pairings.

From the prover’s perspective, Plonk has five rounds in total, each of which computes a new Fiat-Shamir challenge\footnote{A short \href{https://crypto.stackexchange.com/questions/67036/how-to-compute-a-challenge-c-using-fiat-shamir}{description}}. The following are all of the public and private inputs for the PlonK protocol:

\begin{center}
\includegraphics[width=.9\linewidth]{./Frozen-Heart-7.png}
\end{center}

The common pre-processed input contains the values from the trusted setup ceremony (the \(x \cdot [1]_1, \dots, x^{n+2} \cdot [1]_1\) values, where \(x \cdot [1]_1 = g_1^x\) and \(g_1\) is the generator of an elliptic curve group); these are shared by both the prover and verifier.

The big idea of PLONK is to prove that some polynomial \(f(x)\) vanishes on some domain \(H \subset \mathbb{F}\) (treating permutation argument as just another proof). To prove it, we reduce the problem to some other problem. Incrementally, it looks like this \footnote{\href{https://www.cryptologie.net/article/527/understanding-plonk/}{Blog post}}:

\begin{itemize}
\item Proving the previous statement is equivalent to proving that the polynomial is divisible by \(\mathrm{Z}_H(x)\), the polynomial that has all the elements of \(H\) as roots (also called vanishing polynomial). \cite{10.1007/978-3-030-84242-0_27} has more discussions.

\item Which is equivalent to proving the following identity (for some quotient polynomial \(t\):

\[
    f(x) = t(x) \cdot \mathrm{Z}_h(x) \hspace{5 mm} \forall x \in \mathbb{F}
    \]

\item Which is equivalent to proving the identity on some random point \(z\) (from the Schwartz-Zippel lemma):

\[
    f(z) = t(z) \cdot \mathrm{Z}_H(z)
    \]

To prove the last statement, the prover uses of polynomial commitment scheme (KZG) to commit to the polynomial \(f\) and \(t\). The prover then sends the commitments to the verifier. At that point, the verifier has to check that for some random point \(z\): \(f(z) = t(z) \cdot \mathrm{Z}_H(z)\). This is done by sending a random point \(z\) to the prover and doing an "opening" of the commitments at this point: the prover sends the values \(f(z)\) and \(t(z)\) as well as a proof that these are the correct evaluations.

\begin{center}
\includegraphics[width=.9\linewidth]{./plonk-overview.png}
\end{center}
\end{itemize}
\item Main contributions

\begin{itemize}
\item Plonk's universal SNARK requires the prover to compute 5 polynomial commitments, combined with two opening proofs to evaluate the polynomial commitments at a random challenge point. There are two flavors of Plonk: by increasing the proof size by two group elements, the total prover computations can be reduced by \(\approx\) 10\%. The combined degree of the polynomials is either \(9 (n + a)\) (larger proofs) or \(11 (n + a)\) (smaller proofs, reduced verifier work), where \(n\) is the number of multiplication gates and \(a\) is the number of addition gates.

\item Kate commitment \cite{Kate} was improved in PlonK as a batched form, making parallel processing (opening) of commitments for each evaluation point possible. As quoted from \cite{Gabizon2019PLONKPO}, "Ultimately, in the “grand product argument”, this reduces to checking relations between coefficients of polynomials at “neighboring monomials".

\item Plonk defined a low-degree polynomial, which is a slightly simplified version from \cite{Kate} and \cite{inproceedings}, in order to achieve the desired properties for polynomial commitments:
\begin{itemize}
\item Plonk proved that the simplified low-degree polynomial commitment achieved knowledge soundness against algebraic adversaries under the AGM model \cite{10.1007/978-3-319-96881-0_2}.
\item Plonk described the pre-processing (trusted setup) of ranged polynomials. Converting a ranged protocol to a polynomial protocol only incurs one additional prover polynomial.
\end{itemize}
\end{itemize}
\item Improvements

\begin{itemize}
\item SHPLONK: multiple commits
\item TurboPLONK: Custom gates (e.g. EC point addition gates, greatly reducing pairing's computation cost)
\item Redshift
\item Kimchi
\item PLOOKUP: SNARK-unfriendly functions
\item Zexe PLONK: PLONK single-layer rollup with BLS12-377 + BW6-761
\item FFlonk
\item Plonky/Plonky2
\item UntraPlonk
\end{itemize}
\end{itemize}

\subsubsection{Halo}
\label{sec:org7f0c960}
\begin{itemize}
\item Major features
Halo is the first zk-SNARK that supports recursive proof composition without a trusted setup, using the discrete log assumption over normal cycles of elliptic curves, such that proofs constructed with one curve can efficiently verify proofs constructed over the other. Recursion works using “nested amortization”: repeatedly collapsing multiple proofs together over cycles of elliptic curves. Unlike the other new constructs, Halo’s verification time is linear, making it the only new construct that isn’t succinct. However, proof size and verification time in our protocol does not increase with the depth of recursion.
\item Design ideas
The summary of the big idea of Halo is quoted from Vitalik's recent \href{https://vitalik.ca/general/2021/11/05/halo.html}{blog post}:

\begin{quote}
\begin{itemize}
\item We don't know of a way to make a commitment to a size-\(n\) polynomial where evaluations of the polynomial can be verified in \(<O(n)\) time directly. The best result so far is to make a \(log(n)\) sized proof, where all of the work to verify it is logarithmic except for one final \$O(n)\$-time piece.
\item But what we can do is merge multiple proofs together. Given \(m\) proofs of evaluations of size-\(n\) polynomials, you can make a proof that covers all of these evaluations, that takes logarithmic work plus a single size-\(n\) polynomial proof to verify.
\item With some clever trickery, separating out the logarithmic parts from the linear parts of proof verification, we can leverage this to make recursive SNARKs.
\item These recursive SNARKs are actually more efficient than doing recursive SNARKs "directly". In fact, even in contexts where direct recursive SNARKs are possible (eg. proofs with KZG commitments), Halo-style techniques are typically used instead because they are more efficient.
\item It's not just about polynomials; other games used in SNARKs like R1CS can also be aggregated in similar clever ways.
\item No pairings or trusted setups required.
\end{itemize}
\end{quote}
\item Main contributions
\begin{itemize}
\item Polynomial Commitments: with Amortized Succinctness
Halo's main protocol is a variant of Sonic (Plonk for Halo2) \cite{inproceedings} that is adapted to a new polynomial commitment scheme based on the inner product argument (IPA) of \cite{cryptoeprint:2016/263} and \cite{8418611} inspired by Hyrax from \cite{cryptoeprint:2017/1132} (which is itself a variant of the inner product argument first presented in \cite{cryptoeprint:2016/263}, with adaptations from \cite{8418611}). By exploiting the smooth structure of vectors that the verifier must work with, Halo can amortize away (across many proofs) the linear-time verification operation for commitment openings with the assistance of an untrusted third party "helper". Thus the verifier perform the same linear-time operation, but this time only once for the entire batch of proofs. This is similar to the helped variant of the \cite{inproceedings}, except that Halo's approach avoids the need for a trusted setup. Halo achieved smaller proof size than Hyrax from \cite{cryptoeprint:2017/1132} and construct \(U\) using verifier challenge inspired by \cite{8418611}.

\item Nested Amortization: Halo had a novel approach for reducing the verification circuit size by exploiting the amortization strategy (with "helper"). In short, the verification circuit never performs linear-time operations itself, but rather takes the input and (claimed) output of the linear-time operation to be public inputs to the circuit, i.e. they are encoded in the statement being proven. This effectively defers the full verification of the “inner” proof to the verifier, who must also perform a similar linear-time operation to check the “outer” proof. The verifiers can collapse computations on their side together into one with the assistance of a helper. In the recursive context Halo can simply embed the verifier of this amortization argument at each depth of the recursion so as to continually collapse the cost of verifying arguments. The linear-time verification operation is thus only performed once at the end of the recursive chain, and never as part of the verification circuit itself.

\item 2-cycle Curves: Halo performed a search for the 2-cycle curves that had highly 2-adic scalar fields. Both fields are expected to have large 2k primitive roots of unity for applying radix-2 FFTs to accelerate polynomial multiplication. Both fields are expected to have elements of multiplicative order 3 so that we can apply curve endomorphisms to optimize circuits, and that \(gcd(p-1, 5) = gcd(q-1, 5) = 1\) in order to allow instantiating the Rescue hash function with \(\alpha\) = 5. Halo also affectionately referred to their found curves as Tweedledum and Tweedledee. A recent upgrade Halo2 applies Pasta curves: Pallas and Vesta.

\begin{center}
\includegraphics[width=.9\linewidth]{./halo-curves.png}
\end{center}
\end{itemize}
\end{itemize}
\subsubsection{Comparative analysis}
\label{sec:org06ba131}
A brief performance benchmark from \cite{Gabizon2019PLONKPO} can shed some lights on the complexity and efficiency of the above algorithms (\emph{this work} means Plonk):

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./prover-comp.png}
\caption{Prover comparison: \(m\) = number of wires, \(n\) = number of multiplication gates, \(a\) = number of addition gates}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics[width=.9\linewidth]{./verifier-comp.png}
\caption{Verifier comparison per proof, \(P\) = pairing, \(l\) = number of public inputs.}
\end{figure}
\subsubsection{Outlook}
\label{sec:orgc60bb60}
What follows are heavily quoted from \cite{Nitulescu2020zkSNARKsAG}:
\begin{enumerate}
\item Recursive ZK Proofs
\label{sec:org2d5ae6f}
Recursive zero-knowledge SNARKs are one of the most interesting use cases for zero-knowledge technology that are almost ready for practical use. As the name suggests, recursive zkSNARKs unlock the ability to take a proof and verify it inside another proof, allowing for a lot more composability without blowing up proving/verifying times. Besides the real-world composability advantages, recursive zero-knowledge SNARKs are also of great interest because of their use case as a blockchain scaling solution, relying on the succinctness feature of SNARKs to compress secure verification of long blockchains. Mina Protocol is currently implementing such an approach.

It should, however, come as no surprise that efficient recursive ZK SNARK constructions are quite hard to pull off. With the typical method of SNARK constructions that uses elliptic curve fields, the initial, hairy problem to solve is to find a pairing-friendly curve. Attempting to solve for this yields many interesting trade-offs. Many of the options and possibilities have been explored in recent works such as Halo \cite{Bowe2020RecursivePC}, which uses elliptic curve cycles that do not require pairings and Fractal \cite{cryptoeprint:2019/1076}, that eliminates the use of elliptic curves altogether. Overall, the study of efficient recursive ZK proofs is of great importance, and ripe territory for further exploration.
\item Post-Quantum Zero-Knowledge
\label{sec:org74400c8}
Many of the techniques described in previous sections depend on the computational hardness of certain problems, such as computing the discrete logarithm, which have been shown solvable by quantum computers in polynomial time. Therefore, quantum computers may pose a significant threat to the security model and practicality of zkSNARKs that use these techniques. There has been some work on making quantum attack resistant zk-SNARKs. For instance, \cite{10.1145/3243734.3243845} recently proposed a lattice-based zk-SNARK starting with SSP — square span programs (an alternative to the QAP intermediate for boolean circuits). Lattice problems are known to hold against quantum attacks \cite{10.1145/237814.237838}, so this is a very promising line of work.
\item Fiat-Shamir-Compatible Hash Functions
\label{sec:org36bd48e}
Currently Fiat-Shamir heuristic's security is only proven in the Random Oracle Model. It remains an open question whether there exist concrete hash functions that are compatible with the Fiat Shamir heuristic, i.e. if there exist hash functions that guarantee soundness for a transformed proof (and are also compatible with zero-knowledge proofs). There has been a lot of work on this topic, but there is still no known universal hash function that can be proven to be compatible without making strong, somewhat impractical, assumptions yet.
\end{enumerate}
\subsection{Application development}
\label{sec:org48446ad}

A brief overview of recent applications of zkSNARKs are illustrated \hyperref[fig:appdev]{here}:

\begin{sidewaysfigure}[ht]
\begin{center}
\includegraphics[scale=0.5]{/Users/toeinriver/Desktop/zkhw-1/zkSNARKs Application Development.png}
\end{center}
\caption{\label{fig:appdev}Recent development in zkSNARK applications}
\end{sidewaysfigure}

Further work is required on elaborating the digram.

\printbibliography
\end{document}